\newpage
\section{SYS\_04 - Hardware attacks and countermeasures}
\subsection{Introduzione agli Attacchi Hardware}
Gli attacchi hardware sfruttano vulnerabilità fisiche e architetturali delle componenti elettroniche dei sistemi, come CPU, memoria e cache. Tali attacchi sono difficili da rilevare dai software di sicurezza e sfruttano caratteristiche intrinseche dell'hardware, come la temporizzazione, l'uso della cache e l'esecuzione speculativa. Gli attacchi hardware possono includere:

\begin{itemize} \item Attacchi di temporizzazione (Timing Attacks)
\item Attacchi a canale laterale (Side-Channel Attacks)
\item Manipolazioni della cache (Cache Attacks)
\item Attacchi alle funzioni speculative (Speculative Execution Attacks)
\item Attacchi basati su memoria (Memory-based Attacks)
\item Attacchi di RowHammer (attacchi a memoria dinamica)
\end{itemize}

\subsection{Timing e Sicurezza}
Gli attacchi di temporizzazione sfruttano la misurazione dei tempi di esecuzione di operazioni su dati sensibili per ottenere informazioni sui dati stessi. Ad esempio, se un algoritmo impiega più tempo per elaborare determinati dati, \'e possibile dedurre informazioni su di essi, come nel caso delle password o delle chiavi di crittografia.

\paragraph{Uso della Funzione strcmp}
La funzione \texttt{strcmp()} confronta due stringhe carattere per carattere. Se le stringhe sono uguali, la funzione restituisce un valore pari a zero. Tuttavia, se le stringhe differiscono, il tempo impiegato per confrontarle aumenta progressivamente, con il risultato che, più a fondo si arriva nel confronto, maggiore sarà il tempo impiegato. Ciò consente a un attaccante di dedurre quale carattere della stringa \'e corretto, basandosi sul tempo impiegato per completare il confronto.
\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/strcmp.png}
\end{figure}
\paragraph{Timing attack in un Programma di Autenticazione}
Supponiamo che un programma di autenticazione confronti un input (t) con la password corretta (s) usando \texttt{strcmp()}. Se \texttt{t = "password"} e \texttt{s = "password"}, il programma impiega più tempo per confrontare i caratteri quando l'input \'e corretto, rispetto a quando c'\'e un errore, permettendo all'attaccante di inferire gradualmente i caratteri della password.

\subsubsection{Attacchi di Temporizzazione nel Mondo Reale: RSA}
Nel contesto della crittografia, gli attacchi di temporizzazione possono essere utilizzati per ottenere informazioni sulla chiave privata di un sistema come RSA. La decrittazione RSA implica una serie di operazioni di esponentiazione modulare, che dipendono dal valore della chiave privata.

\paragraph{Attacchi alla Decrittazione RSA}
Gli attacchi alla decrittazione RSA si basano sul rilevamento delle differenze nei tempi di esecuzione durante il calcolo dell'esponentiazione modulare. Ad esempio, l'attaccante può inviare cifrati progettati per creare tempi di risposta differenti a causa dei passaggi computazionali coinvolti. Questo fenomeno, noto come il \"gap 0-1\", si verifica quando la decrittazione impiega meno tempo (0) quando certe condizioni sono soddisfatte e più tempo (1) quando altre condizioni richiedono più passaggi computazionali. Osservando queste differenze nei tempi di esecuzione, l'attaccante può inferire parti della chiave privata. Ad esempio, nel caso dell'esponente modulare, la modifica di uno dei bit della chiave può accelerare il calcolo, rivelando informazioni sul valore della chiave.

\paragraph{Algoritmi a Tempo Costante}
Per mitigare i Timing attacks, \'e essenziale utilizzare algoritmi che impiegano lo stesso tempo per ogni confronto, indipendentemente dai dati in ingresso. Un esempio di implementazione sicura di confronto di stringhe potrebbe essere la funzione \texttt{constantTimeStringCompare()} che confronta ogni carattere delle stringhe senza fermarsi fino a quando tutti i caratteri sono stati verificati, impedendo così che l'attaccante possa ottenere informazioni tramite differenze nei tempi di esecuzione.
Ovviamente questo porta ad un peggioramento delle prestazioni, ma aumenta la sicurezza del sistema.
\begin{figure}[H]
\centering
\includegraphics[width=.85\linewidth]{immagini/SYS_04/constTime.png}
\end{figure}

% ======= PREAMBOLO INSERITO QUI =======
\subsection{Preambolo: Side-Channel Attacks e Considerazioni Tecniche}
I \textbf{side-channel attacks} sfruttano effetti micro-architetturali osservabili (tempi di accesso, stato delle cache, aborti transazionali, ecc.) per \emph{inferire} dati che dovrebbero restare isolati tra processi/VM. L’idea chiave è: portare il sottosistema (in primis la gerarchia di cache) in uno \emph{stato noto}, lasciare che la vittima esegua, quindi \emph{misurare} un segnale (latenze, aborti, rumore) che rivela pattern di accesso o contenuti. Tecniche tipiche includono \emph{Prime+Probe}, \emph{Flush+Reload}, \emph{Flush+Flush}, \emph{Evict+Time} e \emph{Prime+Abort}. Questi attacchi possono bypassare l’isolamento del sistema operativo sfruttando cache condivise (L3) o l’SMT per L1.

\paragraph{Fasi operative}
\begin{enumerate}
  \item \textbf{Pre-attack:} selezione del target (set/linea di cache), calibrazione delle \emph{soglie temporali} per distinguere \emph{hit} (veloce) da \emph{miss} (lento).
  \item \textbf{Active attack:} inizializzazione (flush/prime), attesa dell’accesso vittima, misure e analisi degli effetti (tempo di reload/probe, aborti TSX), iterazione finché il segreto (es.\ chiave, nonce) viene ricostruito.
\end{enumerate}

\paragraph{Scoprire i percorsi di codice}
Anche algoritmi con conteggio operazioni costante (es.\ \emph{Montgomery Ladder}) possono rivelare \emph{quale ramo} viene seguito, osservando quali linee di cache vengono toccate: il \emph{timing della cache} permette di inferire il cammino senza cronometrare il numero di operazioni.

\subsubsection{Technical Considerations}
\begin{itemize}
  \item \textbf{Precisione temporale:} servono timer ad alta risoluzione (\texttt{rdtsc}, \texttt{clock\_gettime}); drift e disallineamento tra core introducono rumore.
  \item \textbf{Rumore e variabilità:} contesa CPU e \emph{cache miss} non correlati disturbano le misure; aumentare i campionamenti e usare statistiche robuste (mediana) aiuta.
  \item \textbf{Ottimizzazioni HW/SW:} \emph{branch prediction} ed \emph{speculative execution} alterano i tempi; l’\emph{Hyper-Threading (SMT)} introduce interferenze tra thread sullo stesso core.
  \item \textbf{Scheduling di processo:} l’interleaving del SO riduce la stabilità delle misure; \emph{CPU affinity/pinning} migliora accuratezza e ripetibilità.
  \item \textbf{Gerarchie di cache e prefetch:} L1/L2/L3 hanno latenze diverse che plasmano il segnale; il \emph{prefetching} riduce la predicibilità dei miss e va considerato nel disegno dell’esperimento.
\end{itemize}

\paragraph{Nota pratica (TSX e detection)}
Varianti come \emph{Prime+Abort} sfruttano aborti transazionali come \emph{callback hardware} (senza timing esplicito), ma possono essere limitate disabilitando TSX; in generale la costruzione del canale produce \emph{rumore} misurabile con \emph{Hardware Performance Counters} (HPC), utile per profili di detection—sebbene i contatori differiscano tra vendor e generazioni.
% ======= FINE PREAMBOLO =======

\subsection{Attacchi side channel}
Gli attacchi a canale laterale sfruttano informazioni che possono essere osservate indirettamente durante l'esecuzione di un programma, come il consumo di energia, la radiazione elettromagnetica, o l'accesso alla memoria. Un esempio di attacco a canale laterale \'e quello che sfrutta il comportamento della cache, che può rivelare informazioni su operazioni sensibili come le operazioni crittografiche.

\subsubsection{Timing della Cache}
Quando si leggono i dati dalla memoria, la CPU li legge effettivamente dalla cache, che cerca di servire una richiesta di memoria il più velocemente possibile. Se un attaccante può controllare lo stato della cache, può sfruttare i tempi di accesso per ottenere informazioni sui dati memorizzati. Gli attacchi alla cache si possono dividere in varie tecniche, come \emph{Prime + Probe} e \emph{Flush + Reload}, che mirano a identificare quali dati sono stati caricati nella cache.

\paragraph{Attacchi Flush + Reload}
Il metodo \emph{Flush + Reload} sfrutta il fatto che le linee di cache possono essere ``scaricate'' (flushed) e successivamente ricaricate. Misurando i tempi necessari per ricaricare una linea di cache, un attaccante può determinare se un altro processo ha accesso alla stessa linea di memoria, ottenendo così informazioni sensibili.


\paragraph{Evict + Time}
La tecnica \emph{Evict + Time} combina l’evizione mirata di una linea/set di cache con la misura del \emph{tempo di esecuzione complessivo} della vittima. Prima si lascia girare la vittima per pre-caricare il proprio working set e si stabilisce una \emph{baseline} temporale; poi si \emph{evince} la linea di interesse accedendo ripetutamente a blocchi che mappano nello \emph{stesso cache set} (cache set-associative), quindi si rilancia la vittima: una variazione del tempo indica che quella linea è stata usata e deve essere stata ricaricata dalla memoria.
Non richiede memoria condivisa (a differenza di \emph{Flush+Reload}), funziona su L1/L2/L3 e fornisce un segnale più \emph{coarse} (livello di set) perché si osserva il tempo del programma vittima, non il reload del singolo indirizzo. È utile per inferire \emph{code paths} dipendenti dai dati, ad esempio in implementazioni crittografiche con tabelle, dove il diverso accesso alle entry rivela bit della chiave.
Operativamente è importante poter \emph{triggerare} la vittima più volte, usare timer ad alta risoluzione e barriere (preferire \texttt{rdtscp} o fence per rispettare il program order) e considerare rumore da scheduling, frequency scaling e prefetching, che alterano la stabilità della misura.


\paragraph{Attacchi Prime + Probe}
L'attacco \emph{Prime + Probe} \'e uno degli attacchi più noti alla cache. L'attaccante accede alla cache riempiendola con i propri dati e successivamente fa probing sui dati osservando il tempo necessario per accedere ai dati inseriti. Se un dato \'e stato sostituito da un altro processo, l'accesso sarà più lento, rivelando informazioni sul comportamento del sistema. Questo attacco targetta la cache di livello L1  ma può essere esteso fino ad L3 e può funzionare anche su una VM. Avere successo con questa tipologia di attacchi non \'e cosi semplice visto che l attaccante ha bisogno di un set di indirizzi che collidano.
Una contromisura hardware implementata dalle cache moderne prevede la definizone del mapping della memoria di cache a runtime questo vuol dire che il mapping cambia nel tempo di conseguenza l'attaccante ha una finestra ridotta di tempo per creare il suo eviction set implementando questi step:
\begin{itemize}
    \item scegliere randomicamente N indirizzi di memoria
    \item caricare nella cache accedendo agli indirizzi scelti
    \item gli indirizzi che self-collidono devono essere rimossi dal set
\end{itemize}

\paragraph{Prime + Abort}
\emph{Prime + Abort} sfrutta le transazioni hardware (Intel TSX) come una sorta di \emph{callback} micro-architetturale: si avvia una transazione, si accede \emph{dall’interno} della transazione alla linea di cache bersaglio e poi si osserva se la transazione va in \emph{abort}. L’\emph{abort} segnala un conflitto nel \emph{write set}/\emph{read set} causato dall’attività della vittima su quella linea, per cui \textbf{non serve alcuna misura temporale} (il segnale è l’evento di abort), a differenza di Prime+Probe o Flush+Reload. Requisito chiave: conoscere l’indirizzo preciso da monitorare (granularità a livello di \emph{cache line}).
Nel caso di \textbf{L1}, la transazione include la linea nel \emph{write set}: una scrittura concorrente o un’evizione durante la finestra transazionale provoca abort; essendo L1 privata per core, lo \emph{spionaggio} è limitato a thread co-residente via SMT sullo \emph{stesso} core. In \textbf{L3}, invece, l’accesso transazionale mette la linea nel \emph{read set}: la coerenza cache su letture/scritture di altri core può indurre abort, consentendo osservazioni \emph{cross-core}. In sintesi: nessuna memoria condivisa richiesta, segnale netto (abort), granularità fine (linea), ma dipendenza da TSX e dalla possibilità di ripetere il trigger della vittima. In molti ambienti difensivi TSX può essere disabilitato o limitato; inoltre l’attività di preparazione/sonda introduce rumore rilevabile con \emph{Hardware Performance Counters}.

\paragraph{Flush + Flush}
\emph{Flush + Flush} è una variante di \emph{Flush + Reload} che usa come segnale non il tempo di \emph{reload}, ma il tempo d’esecuzione dell’istruzione di flush (es.\ \texttt{clflush}) sulla \emph{stessa} linea di cache ripetutamente. Poiché \texttt{clflush} impiega un tempo diverso a seconda che la linea sia presente o meno in cache, misurando la latenza del \emph{flush} si può inferire se la vittima ha toccato quella linea. Il vantaggio è duplice: è più \emph{stealthy} (non esegue accessi di reload “visibili”) ed è spesso più veloce; inoltre non richiede necessariamente memoria condivisa. La granularità resta a livello di \emph{cache line} e funziona su L1/L2/L3. Operativamente servono timer ad alta risoluzione e barriere per stabilizzare le misure, mentre rumore da scheduling, prefetching e frequenza CPU può influenzare la separazione delle soglie hit/miss; in ambienti difensivi, l’uso anomalo di \texttt{clflush} può essere monitorato o limitato.


\subsubsection{Meeting Out-of-Order Pipelines: perché conta per la sicurezza}
Nei processori moderni, \textbf{OOO + speculative execution} possono far eseguire alla pipeline \emph{istruzioni fantasma} (transient) che verranno poi scartate a livello architetturale, ma che lasciano \emph{effetti micro-architetturali} (es.\ stato della cache) osservabili con un canale laterale temporale. Questo è il razionale dei \emph{Transient Execution Attacks} (Spectre/Meltdown): anche se il backend “flusha” la pipeline, le tracce rimangono abbastanza a lungo da essere misurate. Il fenomeno riguarda più famiglie di CPU (Intel, AMD, ARM).

\subsubsection{Meltdown: come funziona (Primer)}
\paragraph{Idea chiave}
Meltdown sfrutta il fatto che \textbf{il controllo di privilegio} sugli accessi memoria avviene \emph{dopo} che la pipeline ha già iniziato ad eseguire speculativamente l’accesso. Durante la finestra \emph{transient}, si può \emph{dereferenziare} un indirizzo kernel e usare il valore letto per \emph{indicare} (via stride di pagina) una linea di una \emph{probe array} utente, portandola in cache. Anche se l’accesso privilegiato causa \emph{segfault} e viene annullato architetturalmente, la cache resta “marcata” e il valore del byte si recupera misurando la latenza di reload sui 256 slot dell\'array di probing.

\paragraph{Schema operativo Meltdown}
\begin{enumerate}
  \item \textbf{Flush} della cache.
  \item \textbf{Read} di un byte \(B\)in memoria kernel (vietato in user mode ma \emph{transientmente} eseguito).
  \item \textbf{Utilizzo} del byte \(B\) come offset: accesso a \texttt{probe\_array[B * 4096]} per portare in cache una linea alla volta.
  \item \textbf{Reload \& Time}: si misura quale fra i 256 solt presenti nell array di probing è in cache.
\end{enumerate}

\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/meltdown.png}
\end{figure}

\paragraph{Perché è possibile}
Storicamente, i kernel mappavano l’intero spazio kernel nello \emph{address space} dei processi utente (bit di privilegio nei PTE impediva l’uso lecito, ma l’entry era presente). La finestra \emph{transient} tra \emph{address translation}/\emph{data fetch} e \emph{privilege check} consente l’effetto in cache. Misurare la latenza di accesso alla probe array a fine sequenza rivela il valore reale del byte kernel.

\subsubsection{Fooling the Branch Prediction Unit (BPU)}
La \textbf{Branch Prediction Unit (BPU)} apprende dagli esiti recenti e tenta di anticipare il percorso di esecuzione.
Un attaccante può \emph{avvelenare} (miss-train) la BPU eseguendo ripetutamente un pattern di codice così che la previsione
diventi stabile; cambiando poi il comportamento del codice, la BPU continua a predire il ramo ``allenato'',
consentendo l’esecuzione \emph{transient} di istruzioni non autorizzate. Anche se la pipeline viene poi \emph{flushata},
gli effetti micro–architetturali (es.\ cache) restano osservabili via side–channel.

\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/fool.png}
\end{figure}

\paragraph{Dove si colpisce e perché funziona}
Il \emph{branch target buffer} (BTB) e i predittori (locali/globali, \emph{tournament}) memorizzano storia e bersagli dei salti;
l’attaccante può correlare rami, sfruttare la storia globale e indurre la predizione di un \emph{target} controllato
(anche per salti indiretti). Questa architettura è descritta negli appunti: predittori correlati, tournament predictor,
BTB come piccola cache indicizzata dal \emph{program counter}.

\subsubsection{Spectre Primer v1 (Bounds Check Bypass)}
L’idea classica: si forza la speculazione oltre un controllo di bounds, usando l’indice per selezionare una linea di cache in
una \emph{probe array}; a fine speculazione si misura quale linea è calda e si ricostruisce il dato.
\begin{verbatim}
if (x < array1_size) {
  y = array2[array1[x] * 4096];
}
\end{verbatim}
Anche se la condizione è falsa, durante la finestra speculativa la CPU può accedere a \texttt{array1[x]} fuori limite
e toccare \texttt{array2[ ... ]}, lasciando un’impronta in cache che rivela \texttt{array1[x]}.

\subsubsection{Spectre Primer v2 (BTB Poisoning e Gadget)}
Qui si mira ai \textbf{salti indiretti}: l’attaccante sceglie un \emph{gadget} nell’\emph{executable address space} della vittima
(anche in eBPF), poi \textbf{avvelena il BTB} per far \emph{mispredict} il salto indiretto verso quel gadget,
che viene eseguito speculativamente. Il codice della vittima non è ``buggato'': è sfruttato come gadget per eseguire
accessi che \emph{encodano} il dato in cache. Questo è concettualmente vicino alla ROP.

\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/spectre.png}
\end{figure}
\newpage
\paragraph{Esempio di gadget dalle slide (Windows 10)}
\begin{verbatim}
adc edi, dword ptr [ebx+edx+13BE13BDh]
adc dl,  byte  ptr [edi]
\end{verbatim}
Impostando \texttt{edi} alla base di una \emph{probe array} e \texttt{ebx = m - 0x13BE13BD - edx}, la prima istruzione legge 32 bit
da \texttt{m} e li somma a \texttt{edi}, la seconda \emph{tocca} \texttt{probe[ m ]} portandone la linea in cache. Così si codifica
l’indice \texttt{m} nel canale; l’attaccante controlla i registri e sfrutta la finestra speculativa per far eseguire il gadget.


\paragraph{Requisiti e note}
Il miss–training della BPU deve avvenire sullo stesso core; la lettura del canale (timing di cache) può accadere altrove.

\subsubsection{L1TF (Foreshadow): principio e flusso}
Durante la traduzione degli indirizzi virtuali in indirizzi fisici, i processori Intel eseguono in \emph{parallelo} sia il flusso di traduzione (consultazione della \textbf{TLB}, eventuale \textbf{EPT walk} — \emph{Extended Page Tables} in presenza di \textbf{VM}, e la verifica \textbf{SGX} — \emph{Software Guard eXtensions}) sia la ricerca nella \textbf{cache L1} \emph{VIPT} — \emph{Virtual-Indexed, Physically-Tagged}. In questa finestra \emph{transient}, una entry della tabella delle pagine \emph{non valida} può essere \emph{speculativamente propagata} alla CPU: l’effetto risultante nella L1 rimane osservabile con un side-channel nello \emph{stile Meltdown} (tracce in cache nonostante il flush architetturale). Questo consente a \textbf{L1TF} di \emph{bypassare} le verifiche di protezione del \textbf{SO} durante la navigazione nella tabella delle pagine (caso VM->EPT walk).
\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/checks.png}
\end{figure}
\paragraph{Perché funziona}
Un accesso a una pagina che dovrebbe generare un \emph{terminal fault} (entry non presente o con bit riservati) può avanzare speculativamente abbastanza da lasciare effetti micro–architetturali nella L1. Poiché la ricerca in L1 procede mentre proseguono i controlli di privilegio/validità, l’indirizzo fisico speculativo può pilotare un’operazione di \emph{encode} nel canale (es.\ accessi a una \emph{probe array}); a fine finestra, il dato si ricostruisce misurando i tempi (hit/miss). In questo modo L1TF \textbf{aggira} i tre livelli di controllo: SO (PT walk), VMM/hypervisor (EPT walk) e SGX.

\paragraph{Schema operativo (dalle slide)}
\begin{enumerate}
  \item \textbf{Preparazione PTE/EPT}. Creare una voce per l’indirizzo d’interesse e marcarla \emph{invalida} (bit \emph{present}/\emph{reserved} a~0) così da generare un \emph{terminal fault}. \textit{Nota:} il kernel di norma non consente tali manipolazioni; però un attaccante con un \emph{guest OS} dentro una \textbf{VM} può modificare le proprie \textbf{PT} — \emph{Page Tables}. :contentReference[oaicite:3]{index=3}
  \item \textbf{Trigger transiente}. Causare l’accesso che, pur faultando a livello architetturale, porta temporaneamente il dato in \textbf{L1}.
  \item \textbf{Encode/Leak}. Usare un gadget di encodifica basato su cache (stile Meltdown) e misurare il canale per ricostruire il contenuto protetto. :contentReference[oaicite:4]{index=4}
\end{enumerate}
Nel caso \textbf{VMM}, manipolando le \textbf{PT} del guest si può arrivare a \emph{osservare} memoria dell’host o di altri guest co–locati, sfruttando la finestra transiente e la condivisione delle strutture di traduzione. :contentReference[oaicite:5]{index=5}
\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/vm.png}
\end{figure}




\subsubsection{Mitigating Side-Channel Attacks}
Mitigare gli attacchi a canale laterale è una sfida complessa, poiché molti di questi attacchi si basano su effetti micro-architetturali che sono intrinseci nelle architetture moderne delle CPU. Tuttavia, diverse strategie possono essere adottate per ridurre il rischio o rendere più difficili gli attacchi.

\paragraph{Possible Mitigations and Detection}
Gli attacchi di temporizzazione sono difficili da mitigare completamente, poiché il comportamento delle cache dovrebbe essere modificato in modo sostanziale. Una soluzione teorica sarebbe quella di utilizzare cache a tempo costante, in cui non vi siano differenze nei tempi di accesso alle linee di cache tra hit e miss. Tuttavia, ciò richiederebbe una modifica fondamentale dell'architettura della cache, riducendo drasticamente le prestazioni, rendendo tale soluzione impraticabile per la maggior parte dei sistemi.

\paragraph{Mitigations: the hard way}
Le mitigazioni più efficaci richiedono cambiamenti significativi nell'architettura e nel software:

\begin{itemize}
  \item Rimuovere o limitare l'accesso a timer ad alta risoluzione, come \texttt{rdtsc}, che vengono spesso utilizzati nei side-channel attacks. Questo è difficile, poiché tali timer sono necessari anche per il benchmark delle proprietà hardware.
  \item Consentire che alcune aree di memoria siano marcate come non cacheabili, ma ciò rappresenta una sfida hardware significativa.
  \item Utilizzare le istruzioni \textbf{AES-NI} (Advanced Encryption Standard New Instructions) nelle CPU Intel per eseguire AES, ma la stessa logica non si applica facilmente ad altri algoritmi di crittografia.
  \item Implementare tecniche come \textbf{scatter-gather}, dove i dati segreti non dovrebbero influenzare l'accesso alla memoria su una granularità maggiore di una linea di cache.
  \item Disabilitare le \textbf{TSX} (\emph{Transactional Synchronization Extensions}), che sono utilizzate in alcune operazioni atomiche e che potrebbero essere sfruttate negli attacchi di tipo Prime + Abort.
  \item Disabilitare le pipeline \emph{out-of-order} (OOO), sebbene ciò abbia un impatto significativo sulle prestazioni.
\end{itemize}

\paragraph{Mitigations to L1 Attacks}
Gli attacchi cross-process sulla cache L1 sono possibili solo quando due thread separati condividono la stessa L1. Poiché la cache L1 è privata per ogni core, gli attacchi a L1 sono praticabili solo se si fa affidamento sulla funzionalità \textbf{Simultaneous Multi-Threading (SMT)}. La soluzione più semplice per mitigare questi attacchi è \textbf{disabilitare SMT}, limitando la possibilità di attacchi tra thread di diversi processi che condividono lo stesso core.

\paragraph{Mitigations: the detection way}
L'allestimento di un canale laterale genera sempre un certo rumore nella gerarchia delle cache, soprattutto durante la fase di preparazione di alcuni attacchi. I moderni processori sono dotati di \textbf{Hardware Performance Counters (HPC)}, che consentono di tracciare eventi micro-architetturali e contarli. Questi contatori possono essere utilizzati per osservare il comportamento delle applicazioni in esecuzione nel sistema e attivare contromisure o mitigazioni selettive. Tuttavia, i contatori delle prestazioni non sono stabili tra diversi vendor e generazioni di CPU, quindi questa soluzione potrebbe non essere completamente affidabile.

\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/detection.png}
\end{figure}

\paragraph{Meltdown Mitigation: Kernel Page Table Isolation}
Una delle principali mitigazioni per Meltdown è l'implementazione della \textbf{Kernel Page Table Isolation (KPTI)}. Senza KPTI, lo spazio di memoria utente e kernel sono mappati nello stesso spazio di indirizzamento virtuale, con il kernel che è protetto dai livelli di privilegio. Con KPTI, i due spazi di indirizzamento sono separati, impedendo l'accesso al kernel quando la CPU è in modalità utente. Questo riduce il rischio che un attaccante possa sfruttare Meltdown per accedere ai dati del kernel.

\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/isolation.png}
\end{figure}






\subsubsection{cpu\_entry\_area: Per-CPU Isolation}
La struttura \textbf{cpu\_entry\_area} è utilizzata per isolare i dati specifici del processore, garantendo che le informazioni critiche, come la \emph{Global Descriptor Table (GDT)}, le \emph{Task State Segments (TSS)} e gli stack di eccezione, siano mantenute separate per ciascun core. Questo isolamento è fondamentale per proteggere i dati tra i core e per impedire che informazioni sensibili vengano intercettate o compromesse durante i cambi di contesto. La \textbf{cpu\_entry\_area} è utilizzata per gestire in modo sicuro le transizioni durante gli interrupt e le eccezioni. Quando un processo cambia core, il sistema opera correttamente separando i dati relativi ai diversi core, riducendo il rischio di fuga di dati attraverso le transizioni tra i contesti di esecuzione.

\subsubsection{Double Page General Directory e Switch to CR3}
La Double Page General Directory è una tecnica che separa le tabelle delle pagine tra spazio utente e spazio kernel, utilizzando due pagine di memoria da 4 KB ciascuna per mappare rispettivamente la memoria del kernel e quella utente. Questo approccio riduce il rischio di accessi non autorizzati alla memoria del kernel, come nel caso degli attacchi di tipo Meltdown. Il registro **CR3** è cruciale in questo contesto, poiché contiene il puntatore alla tabella delle pagine attualmente in uso. La transizione tra modalità kernel e utente richiede un aggiornamento del valore di CR3, garantendo l’isolamento tra i due spazi di memoria.

Le transizioni tra modalità si gestiscono tramite macro come \texttt{SWITCH\_TO\_KERNEL\_CR3} e\\ \texttt{SWITCH\_TO\_USER\_CR3\_STACK}, che aggiornano CR3 durante il passaggio tra i due ambienti, assicurando che la separazione tra spazio utente e kernel venga mantenuta. Questo meccanismo è fondamentale per prevenire l'accesso non autorizzato alle risorse di sistema da parte di processi in esecuzione in modalità utente.

\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/cr3.png}
\end{figure}

\subsubsection{Retpoline: Protezione contro gli Attacchi di Branch Target Injection e Retpoline Thunks}
Il \textbf{Retpoline} è una tecnica software progettata per prevenire gli attacchi di \emph{branch target injection}, tipici di Spectre, che sfruttano la predizione dei salti indiretti per manipolare l'esecuzione del codice. Il Retpoline impedisce che la CPU predica i salti indiretti, isolando queste istruzioni dall'esecuzione speculativa e forzando un salto controllato. Questo evita che gli attaccanti manipolino il flusso di esecuzione attraverso la speculazione e l'iniezione di indirizzi di salto non autorizzati. :contentReference[oaicite:0]{index=0}

I \textbf{Retpoline Thunks} sono funzioni che rimandano l'esecuzione di un calcolo fino a quando non è effettivamente necessario, evitando che il processore risolva speculativamente il target di salto. Questo previene la speculazione su indirizzi di ritorno e protegge il flusso di controllo dagli attacchi basati sulla predizione dei salti indiretti. :contentReference[oaicite:1]{index=1}

\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/thunks.png}
\end{figure}

\subsubsection{Prevent Branch Poisoning: IBRS, STIBP, IBPB}
Le vulnerabilità legate alla \emph{branch prediction} possono essere mitigate mediante tecniche come \textbf{IBRS}, \textbf{STIBP} e \textbf{IBPB}, che impediscono la contaminazione della predizione dei rami da parte di software non autorizzato.

\begin{itemize}
  \item \textbf{IBRS} (Indirect Branch Restricted Speculation) è una modalità speciale che viene attivata nei processori per evitare che i predittori dei rami vengano influenzati da istruzioni eseguite prima dell’attivazione di IBRS. Questo garantisce che la predizione del ramo venga isolata, prevenendo gli attacchi di \emph{branch target injection}.
  \item \textbf{STIBP} (Single Thread Indirect Branch Prediction) impedisce la condivisione della predizione dei salti indiretti tra i thread che girano sullo stesso core, limitando le possibilità per un attaccante di sfruttare la predizione dei salti indiretti tra thread diversi.
  \item \textbf{IBPB} (Indirect Branch Predictor Barrier) crea una barriera tra il software che viene eseguito prima e dopo l’impostazione della barriera. Questo impedisce al software che viene eseguito prima della barriera di influenzare la predizione del ramo per il software che viene eseguito dopo.
\end{itemize}
Queste tecniche contribuiscono a ridurre il rischio di attacchi come Spectre, migliorando la sicurezza dei processori moderni contro gli attacchi di predizione dei salti indiretti. :contentReference[oaicite:5]{index=5}


\subsection{RowHammer: Attacco alla Memoria e le sue Mitigazioni}
Il \textbf{RowHammer} è una vulnerabilità fisica che riguarda la memoria DRAM e sfrutta l'effetto di interferenza elettromagnetica tra celle di memoria adiacenti. Quando una riga di memoria viene attivata ripetutamente in modo intensivo, la fluttuazione di tensione risultante può causare un "flip" nei bit della riga vicina, anche se non è direttamente coinvolta nell'operazione. Questo fenomeno, noto come bit flipping, può essere sfruttato da un attaccante per compromettere la sicurezza dei dati memorizzati, alterando il contenuto di celle di memoria vicine e, quindi, manipolando informazioni sensibili.

\begin{figure}[H]
\centering
\includegraphics[width=.5\linewidth]{immagini/SYS_04/rowhammer.png}
\end{figure}

### Meccanismo dell'attacco RowHammer
L'attacco RowHammer si basa su un principio semplice ma efficace: l'attaccante cerca di attivare ripetutamente una riga di memoria specifica, in modo che le fluttuazioni elettromagnetiche causino una modificazione dei dati nelle righe adiacenti. Questo accade perché, durante l'attivazione di una riga, il segnale elettrico può propagarsi nelle righe vicine, causando una carica indotta in queste celle di memoria.

Il RowHammer è particolarmente potente perché sfrutta una caratteristica della memoria DRAM: l'alta densità e la vicinanza fisica delle celle di memoria. Le celle vicine possono essere influenzate da un'operazione di scrittura su una riga diversa, specialmente quando quest'ultima viene attivata ripetutamente. L'attacco non richiede l'accesso privilegiato alla memoria, ma può essere eseguito da un utente malintenzionato che sfrutta la capacità di manipolare l'accesso alle righe di memoria.

### Impatti di RowHammer
L'attacco RowHammer può avere gravi implicazioni per la sicurezza dei sistemi, in particolare in ambienti condivisi, come i sistemi cloud, dove più macchine virtuali (VM) sono eseguite sulla stessa architettura fisica. Se un attaccante è in grado di sfruttare RowHammer, potrebbe corrompere la memoria di un altro processo, rubare chiavi crittografiche o alterare i dati senza che il sistema operativo o le applicazioni possano rilevare l'intrusione.

### Mitigazioni contro RowHammer
Fortunatamente, esistono alcune contromisure per contrastare l'attacco RowHammer, sebbene nessuna di esse offra una protezione perfetta. Le soluzioni più comuni includono:

\begin{itemize}
    \item \textbf{Error Correction Codes (ECC)}: Tecnica che rileva e corregge i bit flip causati dal RowHammer, efficace solo per pochi bit flip per parola di memoria. Non sufficiente se i bit flip sono multipli.
    \item \textbf{Memoria a bassa densità}: Le memorie DRAM con bassa densità o maggiore distanza tra le righe riducono il rischio di interferenze, rendendo più difficile per l'attaccante manipolare più righe contemporaneamente.
    \item \textbf{Refresh rate più alto}: Aumentare la frequenza di aggiornamento della memoria per ridurre il rischio di perdita di carica nelle celle di memoria, ma con impatti sui consumi energetici e le prestazioni.
    \item \textbf{Pseudo-Target Row Refresh (pTRR)}: Tecnica che rinfresca le righe vulnerabili della memoria per evitare bit flip, ma può aumentare i costi e la latenza.
    \item \textbf{Tecniche di partizionamento della memoria}: Il \emph{Memory Partitioning} separa le righe di memoria, riducendo l'accesso non autorizzato, e può essere implementato hardware o software.
    \item \textbf{Virtualizzazione e isolamento hardware}: L'isolamento tra macchine virtuali (VM) riduce il rischio che un attaccante acceda alla memoria di altre VM.
\end{itemize}




\subsection{Memory Performance Attacks: Attacchi alle Prestazioni della Memoria}
Gli \textbf{attacchi alle prestazioni della memoria} mirano a sfruttare il comportamento non ottimale dei sistemi DRAM, in particolare durante la gestione della memoria in scenari multi-core. Questi attacchi sfruttano le caratteristiche di programmazione e accesso alla memoria, come la gestione dei buffer di riga e la concorrenza tra processi, per compromettere le prestazioni o, in alcuni casi, causare un Denial of Service (DoS) alla memoria.

\paragraph{Denial of Service nei Sistemi Multi-Core}
Nei sistemi multi-core, i pianificatori di memoria DRAM sono progettati per chip a singolo core, il che comporta inefficienze nelle operazioni di memoria quando più core tentano di accedere a risorse condivise. Ogni banco di memoria ha un buffer di riga e l'accesso alla memoria avviene attraverso questo buffer. Se due o più thread accedono simultaneamente a diverse righe di memoria, il sistema potrebbe dover risolvere conflitti, causando ritardi nei tempi di accesso alla memoria. Questo tipo di attacco può portare a rallentamenti significativi e persino al blocco dei processi, creando un attacco DoS a livello di memoria.

\paragraph{Funzionamento degli Attacchi a Memoria Multi-Banca}
Le memorie DRAM moderne hanno più banchi, ciascuno con un buffer di riga. Il \textbf{piano di accesso alla memoria} si occupa di risolvere le richieste in base alla disponibilità di ciascun banco. In uno scenario ottimale, la schedulazione della memoria cerca di minimizzare i conflitti tra le righe, ma nei sistemi multi-core il conflitto tra i processi che accedono simultaneamente agli stessi banchi o righe può compromettere gravemente le prestazioni. Gli attacchi in questo contesto sfruttano l'accesso a righe di memoria che non sono ottimizzate per l'esecuzione parallela, causando inefficienze nel sistema.

\paragraph{Scheduling della Memoria e Contesa tra Banchi}
Il piano di accesso \textbf{FR-FCFS} (First-Ready, First-Come, First-Serve) ottimizza le richieste che si allineano con la riga già disponibile nel buffer, riducendo i conflitti. Tuttavia, non gestisce bene i conflitti tra banchi diversi, causando inefficienze, specialmente quando un thread con alta località di riga accede a righe vicine. Inoltre, poiché i banchi di memoria condividono un bus centrale, un thread che accede frequentemente alla memoria può ridurre le risorse disponibili per altri thread, creando condizioni di contesa che rallentano l'accesso e, in alcuni casi, possono portare a un Denial of Service (DoS). Gli attaccanti possono sfruttare queste inefficienze con tecniche di scheduling avanzate.

\paragraph{Mitigazioni e Strategie di Ottimizzazione}
La protezione contro gli attacchi di prestazione della memoria dipende principalmente da tecniche di ottimizzazione a livello hardware e software. Alcuni approcci includono:

\begin{itemize}
  \item \textbf{Piani di accesso a memoria più avanzati}, come quelli che minimizzano i conflitti di accesso tra banchi.
  \item \textbf{Affinità CPU} (CPU affinity), che assicura che i thread che accedono frequentemente a determinati dati vengano eseguiti sullo stesso core per migliorare la località di riferimento.
  \item \textbf{Schedulazione intelligente delle richieste di memoria}, che ottimizza l'allocazione delle risorse di memoria per ridurre il rischio di conflitti tra i thread.
  \item \textbf{Memoria di tipo HBM (High Bandwidth Memory)} che riduce la latenza e le collisioni nell'accesso alla memoria.
\end{itemize}

Tuttavia, come per la maggior parte delle soluzioni hardware, esiste un compromesso tra prestazioni e sicurezza, quindi è necessario un bilanciamento tra l'implementazione di difese contro gli attacchi a prestazione della memoria e l'ottimizzazione per le prestazioni generali del sistema.
